{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-09-29T10:08:35.528710Z",
     "start_time": "2024-09-29T10:08:35.521797Z"
    }
   },
   "source": [
    "import os\n",
    "from langchain.docstore.document import Document\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain import hub\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model='gemini-1.5-flash', temperature=0.9)\n"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T10:08:42.647062Z",
     "start_time": "2024-09-29T10:08:41.193736Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import logging\n",
    "import zipfile\n",
    "\n",
    "import requests\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)\n",
    "\n",
    "data_url = \"https://storage.googleapis.com/benchmarks-artifacts/langchain-docs-benchmarking/cj.zip\"\n",
    "result = requests.get(data_url)\n",
    "filename = \"cj.zip\"\n",
    "with open(filename, \"wb\") as file:\n",
    "    file.write(result.content)\n",
    "\n",
    "with zipfile.ZipFile(filename, \"r\") as zip_ref:\n",
    "    zip_ref.extractall()"
   ],
   "id": "7ad3accef0742a47",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T10:08:44.443737Z",
     "start_time": "2024-09-29T10:08:43.687275Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "\n",
    "loader = PyPDFLoader(\"./cj/cj.pdf\")\n",
    "docs = loader.load()\n",
    "tables = []\n",
    "texts = [d.page_content for d in docs]\n",
    "full_document = \" \".join(texts)\n"
   ],
   "id": "80e750a1f8dd92fc",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T10:08:52.277986Z",
     "start_time": "2024-09-29T10:08:46.223278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_model = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")"
   ],
   "id": "610d9e8fc472f7f3",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: all-MiniLM-L6-v2\n",
      "/opt/anaconda3/envs/DigiSchool/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1617: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be deprecated in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n",
      "INFO:sentence_transformers.SentenceTransformer:Use pytorch device_name: mps\n",
      "INFO:sentence_transformers.SentenceTransformer:Load pretrained SentenceTransformer: sentence-transformers/all-MiniLM-L6-v2\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T10:08:58.966281Z",
     "start_time": "2024-09-29T10:08:58.963073Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Split the full document into smaller chunks using RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_text(full_document)\n"
   ],
   "id": "be9dc973562bd238",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T10:09:02.098060Z",
     "start_time": "2024-09-29T10:09:02.094769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Create document objects from the splits\n",
    "split_docs = [Document(page_content=chunk) for chunk in splits]  # Ensure each chunk is a Document object\n"
   ],
   "id": "67ae35d0e7469750",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T09:52:23.635517Z",
     "start_time": "2024-09-29T09:52:22.201769Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Embed the document chunks using the embedding model and store them in a vectorstore\n",
    "vectorstore = Chroma.from_documents(documents=split_docs, embedding=embedding_model)"
   ],
   "id": "3707eb4d75b22754",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:chromadb.telemetry.product.posthog:Anonymized telemetry enabled. See                     https://docs.trychroma.com/telemetry for more information.\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T09:56:22.281317Z",
     "start_time": "2024-09-29T09:56:21.565887Z"
    }
   },
   "cell_type": "code",
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "prompt_template = hub.pull(\"rlm/rag-prompt\")"
   ],
   "id": "f457a8da7890212",
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T09:54:52.151517Z",
     "start_time": "2024-09-29T09:54:52.148845Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ],
   "id": "f339d15b7a2c5c20",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T09:56:28.964446Z",
     "start_time": "2024-09-29T09:56:28.960757Z"
    }
   },
   "cell_type": "code",
   "source": [
    "rag_chain = (\n",
    "            {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "            | prompt_template\n",
    "            | llm\n",
    "            | StrOutputParser()\n",
    "        )"
   ],
   "id": "a502e3e1bb0446e3",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T09:58:01.743031Z",
     "start_time": "2024-09-29T09:57:57.552761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "user_prompt = \"help me summarize this\"\n",
    "\n",
    "res = rag_chain.invoke(user_prompt)"
   ],
   "id": "14c2ef6e3bdfc1be",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1727603877.958992 1791289 fork_posix.cc:77] Other threads are currently calling into gRPC, skipping fork() handlers\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-09-29T09:58:07.545163Z",
     "start_time": "2024-09-29T09:58:07.539642Z"
    }
   },
   "cell_type": "code",
   "source": "res",
   "id": "beb70addfbd64e3c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This article from Clouded Judgement discusses the EV/NTM revenue multiple divided by NTM consensus growth expectations. The author analyzes the median multiples for different growth categories, including high growth, mid growth, and low growth. The article also notes that past performance is not indicative of future results. \\n'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 28
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
